{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VarAutoEncoders.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ZQGL7buKdZzG",
        "colab_type": "code",
        "outputId": "d81eb168-5750-49b4-d862-a36bff3b3f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9704
        }
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn as sk\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.misc import imsave\n",
        "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
        "\n",
        "\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "distributions = tf.distributions\n",
        "\n",
        "####Delete all flags before declare#####\n",
        "\n",
        "def del_all_flags(FLAGS):\n",
        "  flags_dict = FLAGS._flags()    \n",
        "  keys_list = [keys for keys in flags_dict]    \n",
        "  for keys in keys_list:    \n",
        "    FLAGS.__delattr__(keys)\n",
        "\n",
        "del_all_flags(tf.flags.FLAGS)\n",
        "tf.reset_default_graph()\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('data_dir', 'data/', 'Directory for data')\n",
        "flags.DEFINE_string('logdir', 'log/', 'Directory for logs')\n",
        "\n",
        "# For making plots:\n",
        "# flags.DEFINE_integer('latent_dim', 2, 'Latent dimensionality of model')\n",
        "# flags.DEFINE_integer('batch_size', 64, 'Minibatch size')\n",
        "# flags.DEFINE_integer('n_samples', 10, 'Number of samples to save')\n",
        "# flags.DEFINE_integer('print_every', 10, 'Print every n iterations')\n",
        "# flags.DEFINE_integer('hidden_size', 200, 'Hidden size for neural networks')\n",
        "# flags.DEFINE_integer('n_iterations', 1000, 'number of iterations')\n",
        "\n",
        "# For bigger model:\n",
        "flags.DEFINE_integer('latent_dim', 100, 'Latent dimensionality of model')\n",
        "flags.DEFINE_integer('batch_size', 64, 'Minibatch size')\n",
        "flags.DEFINE_integer('n_samples', 1, 'Number of samples to save')\n",
        "flags.DEFINE_integer('print_every', 1000, 'Print every n iterations')\n",
        "flags.DEFINE_integer('hidden_size', 200, 'Hidden size for neural networks')\n",
        "flags.DEFINE_integer('n_iterations', 5000, 'number of iterations')\n",
        "flags.DEFINE_float('threshold', 8.5, 'Threshold for recon probab')\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def inference_network(x, latent_dim, hidden_size):\n",
        "  \"\"\"Construct an inference network parametrizing a Gaussian.\n",
        "\n",
        "  Args:\n",
        "    x: A batch of MNIST digits.\n",
        "    latent_dim: The latent dimensionality.\n",
        "    hidden_size: The size of the neural net hidden layers.\n",
        "\n",
        "  Returns:\n",
        "    mu: Mean parameters for the variational family Normal\n",
        "    sigma: Standard deviation parameters for the variational family Normal\n",
        "  \"\"\"\n",
        "  with slim.arg_scope([slim.fully_connected], activation_fn=tf.nn.relu):\n",
        "    net = slim.flatten(x)\n",
        "    net = slim.fully_connected(net, hidden_size)\n",
        "    net = slim.fully_connected(net, hidden_size)\n",
        "    gaussian_params = slim.fully_connected(\n",
        "        net, latent_dim * 2, activation_fn=None)\n",
        "  # The mean parameter is unconstrained\n",
        "  mu = gaussian_params[:, :latent_dim]\n",
        "  # The standard deviation must be positive. Parametrize with a softplus\n",
        "  sigma = tf.nn.softplus(gaussian_params[:, latent_dim:])\n",
        "  return mu, sigma\n",
        "\n",
        "\n",
        "def generative_network(z, hidden_size):\n",
        "  \"\"\"Build a generative network parametrizing the likelihood of the data\n",
        "\n",
        "  Args:\n",
        "    z: Samples of latent variables\n",
        "    hidden_size: Size of the hidden state of the neural net\n",
        "\n",
        "  Returns:\n",
        "    bernoulli_logits: logits for the Bernoulli likelihood of the data\n",
        "  \"\"\"\n",
        "  with slim.arg_scope([slim.fully_connected], activation_fn=tf.nn.relu):\n",
        "    net = slim.fully_connected(z, hidden_size)\n",
        "    net = slim.fully_connected(net, hidden_size)\n",
        "    bernoulli_logits = slim.fully_connected(net, 784, activation_fn=None)\n",
        "    bernoulli_logits = tf.reshape(bernoulli_logits, [-1, 28, 28, 1])\n",
        "  return bernoulli_logits\n",
        "\n",
        "\n",
        "def train():\n",
        "  # Train a Variational Autoencoder on MNIST\n",
        "\n",
        "  # Input placeholders\n",
        "  with tf.name_scope('data'):\n",
        "    x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "    tf.summary.image('data', x)\n",
        "  \n",
        "  with tf.variable_scope('variational'):\n",
        "    q_mu, q_sigma = inference_network(x=x,\n",
        "                                      latent_dim=FLAGS.latent_dim,\n",
        "                                      hidden_size=FLAGS.hidden_size)\n",
        "    # The variational distribution is a Normal with mean and standard\n",
        "    # deviation given by the inference network\n",
        "    q_z = distributions.Normal(loc=q_mu, scale=q_sigma)\n",
        "    assert q_z.reparameterization_type == distributions.FULLY_REPARAMETERIZED\n",
        "    \n",
        "  with tf.variable_scope('model'):\n",
        "    # The likelihood is Bernoulli-distributed with logits given by the\n",
        "    # generative network\n",
        "    mySample = q_z.sample()\n",
        "    p_x_given_z_logits = generative_network(z=mySample,\n",
        "                                            hidden_size=FLAGS.hidden_size)\n",
        "    p_x_given_z = distributions.Bernoulli(logits=p_x_given_z_logits)\n",
        "    posterior_predictive_samples = p_x_given_z.sample()\n",
        "    tf.summary.image('posterior_predictive',\n",
        "                     tf.cast(posterior_predictive_samples, tf.float32))\n",
        "\n",
        "  # Take samples from the prior\n",
        "  with tf.variable_scope('model', reuse=True):\n",
        "    p_z = distributions.Normal(loc=np.zeros(FLAGS.latent_dim, dtype=np.float32),\n",
        "                               scale=np.ones(FLAGS.latent_dim, dtype=np.float32))\n",
        "    p_z_sample = p_z.sample(FLAGS.n_samples)\n",
        "    p_x_given_z_logits = generative_network(z=p_z_sample,\n",
        "                                            hidden_size=FLAGS.hidden_size)\n",
        "    prior_predictive = distributions.Bernoulli(logits=p_x_given_z_logits)\n",
        "    prior_predictive_samples = prior_predictive.sample()\n",
        "    tf.summary.image('prior_predictive',\n",
        "                     tf.cast(prior_predictive_samples, tf.float32))\n",
        "\n",
        "#   # Take samples from the prior with a placeholder\n",
        "#   with tf.variable_scope('model', reuse=True):\n",
        "#     z_input = tf.placeholder(tf.float32, [None, FLAGS.latent_dim])\n",
        "#     p_x_given_z_logits = generative_network(z=z_input,\n",
        "#                                             hidden_size=FLAGS.hidden_size)\n",
        "#     prior_predictive_inp = distributions.Bernoulli(logits=p_x_given_z_logits)\n",
        "#     prior_predictive_inp_sample = prior_predictive_inp.sample()\n",
        "\n",
        "  # Build the evidence lower bound (ELBO) or the negative loss\n",
        "  kl = tf.reduce_sum(distributions.kl_divergence(q_z, p_z), 1)\n",
        "#   tense = p_x_given_z.log_prob(x)\n",
        "  expected_log_likelihood = tf.reduce_sum(p_x_given_z.log_prob(x),\n",
        "                                          [1, 2, 3])\n",
        "\n",
        "  # print \"p_x_given_z.log_prob(x).shape\", p_x_given_z.log_prob(x).shape\n",
        "  # shapeTensor =  tf.shape(p_x_given_z.log_prob(x))\n",
        "\n",
        "  elbo = tf.reduce_sum(expected_log_likelihood - kl, 0)\n",
        "\n",
        "  optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
        "\n",
        "  train_op = optimizer.minimize(-elbo)\n",
        "\n",
        "  # Merge all the summaries\n",
        "  summary_op = tf.summary.merge_all()\n",
        "\n",
        "  init_op = tf.global_variables_initializer()\n",
        "\n",
        "  # Run training\n",
        "  sess = tf.InteractiveSession()\n",
        "  sess.run(init_op)\n",
        "\n",
        "  mnist = read_data_sets(FLAGS.data_dir, one_hot=True)\n",
        "\n",
        "  train, test = mnist.train, mnist.test\n",
        "  trainX, trainY, testX, testY = train.images, train.labels, test.images, test.labels\n",
        "\n",
        "  k = 0\n",
        "  # omit all examples of the class k\n",
        "  mask = trainY[:,k]==0\n",
        "  trainX = trainX[mask]\n",
        "  trainY = trainY[mask]\n",
        "  \n",
        "  n = trainX.shape[0]\n",
        "\n",
        "  print('Saving TensorBoard summaries and images to: %s' % FLAGS.logdir)\n",
        "  train_writer = tf.summary.FileWriter(FLAGS.logdir, sess.graph)\n",
        "\n",
        "  # Get fixed MNIST digits for plotting posterior means during training\n",
        "  np_x_fixed, np_y = test.next_batch(5000)\n",
        "#   print(np_x_fixed.shape)\n",
        "  np_x_fixed = np_x_fixed.reshape(5000, 28, 28, 1)\n",
        "  np_x_fixed = (np_x_fixed > 0.5).astype(np.float32)\n",
        "  np_y = np.asarray(np_y[:,k]==1, dtype=np.float32)\n",
        "\n",
        "  t0 = time.time()\n",
        "  for i in range(FLAGS.n_iterations):\n",
        "    # Re-binarize the data at every batch; this improves results\n",
        "#     np_x, _ = train.next_batch(FLAGS.batch_size)\n",
        "    batch = np.floor(np.random.rand(FLAGS.batch_size)*n).astype(int)\n",
        "    np_x = trainX[batch,:]\n",
        "#     print(np_x.shape)\n",
        "#     np_x += np.random.randn(np_x.shape)\n",
        "    np_x = np_x.reshape(FLAGS.batch_size, 28, 28, 1)\n",
        "    np_x = (np_x > 0.5).astype(np.float32)\n",
        "    #     print np_x.shape\n",
        "    sess.run(train_op, {x: np_x})\n",
        "#     print samples.shape\n",
        "\n",
        "    # Print progress and save samples every so often\n",
        "    if i % FLAGS.print_every == 0:\n",
        "      np_elbo, summary_str = sess.run([elbo, summary_op], {x: np_x})\n",
        "      train_writer.add_summary(summary_str, i)\n",
        "      print('Iteration: {0:d} ELBO: {1:.3f} s/iter: {2:.3e}'.format(\n",
        "          i,\n",
        "          np_elbo / FLAGS.batch_size,\n",
        "          (time.time() - t0) / FLAGS.print_every))\n",
        "      t0 = time.time()\n",
        "\n",
        "      # Save samples\n",
        "#       np_posterior_samples, np_prior_samples = sess.run(\n",
        "#           [posterior_predictive_samples, prior_predictive_samples], {x: np_x})\n",
        "#       for k in range(FLAGS.n_samples):\n",
        "#         f_name = os.path.join(\n",
        "#             FLAGS.logdir, 'iter_%d_posterior_predictive_%d_data.jpg' % (i, k))\n",
        "#         imsave(f_name, np_x[k, :, :, 0])\n",
        "#         f_name = os.path.join(\n",
        "#             FLAGS.logdir, 'iter_%d_posterior_predictive_%d_sample.jpg' % (i, k))\n",
        "#         imsave(f_name, np_posterior_samples[k, :, :, 0])\n",
        "#         f_name = os.path.join(\n",
        "#             FLAGS.logdir, 'iter_%d_prior_predictive_%d.jpg' % (i, k))\n",
        "#         imsave(f_name, np_prior_samples[k, :, :, 0])\n",
        "\n",
        "#       # Plot the posterior predictive space\n",
        "#       if FLAGS.latent_dim == 2:\n",
        "#         np_q_mu = sess.run(q_mu, {x: np_x_fixed})\n",
        "#         cmap = mpl.colors.ListedColormap(sns.color_palette(\"husl\"))\n",
        "#         f, ax = plt.subplots(1, figsize=(6 * 1.1618, 6))\n",
        "#         im = ax.scatter(np_q_mu[:, 0], np_q_mu[:, 1], c=np.argmax(np_y, 1), cmap=cmap,\n",
        "#                         alpha=0.7)\n",
        "#         ax.set_xlabel('First dimension of sampled latent variable $z_1$')\n",
        "#         ax.set_ylabel('Second dimension of sampled latent variable mean $z_2$')\n",
        "#         ax.set_xlim([-10., 10.])\n",
        "#         ax.set_ylim([-10., 10.])\n",
        "#         f.colorbar(im, ax=ax, label='Digit class')\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(os.path.join(FLAGS.logdir,\n",
        "#                                  'posterior_predictive_map_frame_%d.png' % i))\n",
        "#         plt.close()\n",
        "\n",
        "#         nx = ny = 20\n",
        "#         x_values = np.linspace(-3, 3, nx)\n",
        "#         y_values = np.linspace(-3, 3, ny)\n",
        "#         canvas = np.empty((28 * ny, 28 * nx))\n",
        "#         for ii, yi in enumerate(x_values):\n",
        "#           for j, xi in enumerate(y_values):\n",
        "#             np_z = np.array([[xi, yi]])\n",
        "#             x_mean = sess.run(prior_predictive_inp_sample, {z_input: np_z})\n",
        "#             canvas[(nx - ii - 1) * 28:(nx - ii) * 28, j *\n",
        "#                    28:(j + 1) * 28] = x_mean[0].reshape(28, 28)\n",
        "#         imsave(os.path.join(FLAGS.logdir,\n",
        "#                             'prior_predictive_map_frame_%d.png' % i), canvas)\n",
        "#         # plt.figure(figsize=(8, 10))\n",
        "#         # Xi, Yi = np.meshgrid(x_values, y_values)\n",
        "#         # plt.imshow(canvas, origin=\"upper\")\n",
        "#         # plt.tight_layout()\n",
        "#         # plt.savefig()\n",
        "\n",
        "  # # Make the gifs\n",
        "  # if FLAGS.latent_dim == 2:\n",
        "  #   os.system(\n",
        "  #       'convert -delay 15 -loop 0 {0}/posterior_predictive_map_frame*png {0}/posterior_predictive.gif'\n",
        "  #       .format(FLAGS.logdir))\n",
        "  #   os.system(\n",
        "  #       'convert -delay 15 -loop 0 {0}/prior_predictive_map_frame*png {0}/prior_predictive.gif'\n",
        "  #       .format(FLAGS.logdir))\n",
        "\n",
        "  # evaluate the test samples\n",
        "  np_posterior_samples, np_prior_samples = sess.run(\n",
        "      [posterior_predictive_samples, prior_predictive_samples], {x: np_x_fixed})\n",
        "  norm_vec = np.linalg.norm((np_x_fixed - np_posterior_samples).reshape(5000,784), axis=1)\n",
        "#   np_prior_samples[k, :, :, 0] \n",
        "  \n",
        "  anomaly_vector = np.asarray(norm_vec > FLAGS.threshold, np.float32)\n",
        "  y_pred = anomaly_vector\n",
        "  y_real = np_y\n",
        "  val_accuracy = np.sum(y_pred == y_real)*1.0/5000.0\n",
        "#   y_truth = tf.placeholder(tf.float32, [5000,])\n",
        "#   corr_pred = tf.equal(y_p, y_truth)\n",
        "#   accuracy = tf.reduce_mean(tf.cast(corr_pred, \"float\"))\n",
        "\n",
        "#   val_accuracy, y_pred, rp = sess.run([accuracy, y_p, expected_log_likelihood], feed_dict={x:np_x_fixed, y_truth:np_y})\n",
        "\n",
        "  for i in xrange(100):\n",
        "    print norm_vec[i]\n",
        "  print \"validation accuracy:\", val_accuracy\n",
        "#   y_true = np.asarray(np.argmax(np_y,1), np.float32)\n",
        "#   print y_real, y_pred\n",
        "  print np.sum(y_pred)\n",
        "  print np.sum(y_real)\n",
        "  \n",
        "  print \"Precision\", sk.metrics.precision_score(y_real, y_pred)\n",
        "  print \"Recall\", sk.metrics.recall_score(y_real, y_pred)\n",
        "  print \"f1_score\", sk.metrics.f1_score(y_real, y_pred)\n",
        "  print \"confusion_matrix\"\n",
        "  print sk.metrics.confusion_matrix(y_real, y_pred)  \n",
        "  fpr, tpr, thresholds = sk.metrics.roc_curve(y_real, y_pred)\n",
        "  auc = sk.metrics.roc_auc_score(y_real, y_pred)\n",
        "  print \"AUC=\", auc\n",
        "\n",
        "def main(_):\n",
        "  if tf.gfile.Exists(FLAGS.logdir):\n",
        "    tf.gfile.DeleteRecursively(FLAGS.logdir)\n",
        "  tf.gfile.MakeDirs(FLAGS.logdir)\n",
        "  train()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "Saving TensorBoard summaries and images to: log/\n",
            "(64, 784)\n",
            "Iteration: 0 ELBO: -529.586 s/iter: 7.158e-05\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n",
            "(64, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ba2b93b5349d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-ba2b93b5349d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-ba2b93b5349d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mnp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp_x\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m#     print np_x.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp_x\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;31m#     print samples.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}